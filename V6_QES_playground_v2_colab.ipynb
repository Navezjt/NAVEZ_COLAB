{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iwe04m1G10P"
      },
      "source": [
        "# Playground V2, a Quick-Eyed Sky fork\n",
        "\n",
        "Page\n",
        "https://blog.playgroundai.com/playground-v2\n",
        "\n",
        "Model\n",
        "https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic\n",
        "\n",
        "License\n",
        "https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic/blob/main/LICENSE.md\n",
        "<br><br>\n",
        "\n",
        "This is a straightforward fork that incorporates the following enhancements:<b>\n",
        "\n",
        "- All generated images are directly saved to your Google Drive.\n",
        "\n",
        "- Dynamic Prompting (Dynamic Prompting is a simple trick that chooses randomly words in lists written like this: \"Photo of a {car|train|truck} in the {sun|rain|evening|mist}).\n",
        "\n",
        "- Settings are saved too (in a .txt), for each set.\n",
        "\n",
        "- Batch processing of up to 200 images is now possible.\n",
        "\n",
        "- Image dimensions have been increased to 2048 pixels.\n",
        "\n",
        "- The Gradio interface has been expanded for a more intuitive user experience.</b><br>\n",
        "\n",
        "You can change things (steps) directly in the code if you wish. The Huggingface page say: \"Note: It is recommend to use guidance_scale=3.0.\"<br><br>\n",
        "Click on the link when all is installed (\"Running on public URL:\").<br>\n",
        "\n",
        "\n",
        "<br>Have fun!<br><br>\n",
        "\n",
        "- Patreon: https://www.patreon.com/Quick_Eyed_Sky<br>\n",
        "- YouTube: <b>Quick-Eyed Sky</b><br><br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Quick-Eyed-Sky/Images/main/3b74994e-67aa-4118-b8b6-313feb37fb95.png\" width=\"100%\" alt=\"Alt text\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§ V6 QES_playground_v2_Navez âš¡\n",
        "\n",
        "*if you find this helpful consider becoming a member on patreon, subscribe to my youtube for Ai applications guides*\n",
        "\n",
        "[![Patreon](https://img.shields.io/badge/Patreon-Support-orange?style=rounded-square&logo=patreon)](https://www.patreon.com/user?u=98917275)\n",
        "[![Youtube](https://img.shields.io/badge/Youtube-Subscribe-red?style=rounded-square&logo=youtube)](https://www.youtube.com/@clementetumbajulcan4712)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-Visit-blue?style=rounded-square&logo=github)](https://github.com/Navezjt)\n",
        "[![Huggingface](https://img.shields.io/badge/Huggingface-visit-yellow?style=rounded-square&logo=huggingface)](https://huggingface.co/JCTN)\n",
        "[![Instagram](https://img.shields.io/badge/Instagarm-Follow-pink?style=rounded-square&logo=Instagram)](https://Instagram.com/joeltumbajulca)\n"
      ],
      "metadata": {
        "id": "hGZJP0143Aar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # <font color=\"#0497e0\">**JOEL CTN**</font>UI + <font color=\"#4684a3\"> RADIO\n",
        "%%html\n",
        "<b>Press play on the music player(Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"http://stream.zeno.fm/vq4s9m2sg48uv\" controls>"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WfQa3s5-3cQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2wefLmQHD6b",
        "outputId": "7843d0bd-58d0-4f5a-cca6-7c78152269d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-456b51d6-2825-7818-2552-e7766a38e292)\n"
          ]
        }
      ],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKcOwT4F-VXU",
        "outputId": "7bfa4ed2-e0e5-48ad-9e83-1a3263ab93a4",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title # <font color=\"#0497e0\">**JOEL CTN**</font>UI + <font color=\"#4684a3\"> Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK4RsonOvoD4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Installation\n",
        "!pip install -q diffusers accelerate gradio\n",
        "\n",
        "import os\n",
        "import random\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/Playground\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFPxlmRX620K",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Image Generation Settings\n",
        "DESCRIPTION = \"\"\"# Quick-Eyed Sky fork of Playground v2\"\"\"\n",
        "if not torch.cuda.is_available():\n",
        "    DESCRIPTION += \"\\n<p>Running on CPU ðŸ¥¶ This demo may not work on CPU.</p>\"\n",
        "\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "CACHE_EXAMPLES = torch.cuda.is_available() and os.getenv(\"CACHE_EXAMPLES\", \"1\") == \"1\"\n",
        "MAX_IMAGE_SIZE = int(os.getenv(\"MAX_IMAGE_SIZE\", \"2048\"))\n",
        "USE_TORCH_COMPILE = os.getenv(\"USE_TORCH_COMPILE\", \"0\") == \"1\"\n",
        "ENABLE_CPU_OFFLOAD = os.getenv(\"ENABLE_CPU_OFFLOAD\", \"0\") == \"1\"\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Problem with \"secret\"? Click on the key in the left menu and create a HF_TOKEN with your Hugging Face toke\n",
        "# from google.colab import userdata\n",
        "# userdata.get('HF_TOKEN')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "        \"playgroundai/playground-v2-1024px-aesthetic\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        add_watermarker=False,\n",
        "        variant=\"fp16\"\n",
        "    )\n",
        "    if ENABLE_CPU_OFFLOAD:\n",
        "        pipe.enable_model_cpu_offload()\n",
        "    else:\n",
        "        pipe.to(device)\n",
        "        print(\"Loaded on Device!\")\n",
        "\n",
        "    if USE_TORCH_COMPILE:\n",
        "        pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)\n",
        "        print(\"Model Compiled!\")\n",
        "\n",
        "def save_image(img, folder_path):\n",
        "    unique_name = str(uuid.uuid4()) + \".png\"\n",
        "    full_path = os.path.join(folder_path, unique_name)\n",
        "    img.save(full_path)\n",
        "    return full_path\n",
        "\n",
        "def process_dynamic_prompt(prompt):\n",
        "    while '{' in prompt:\n",
        "        start = prompt.find('{')\n",
        "        end = prompt.find('}', start)\n",
        "        if end == -1:  # Just in case there's an unmatched '{'\n",
        "            break\n",
        "        options = prompt[start+1:end].split('|')\n",
        "        choice = random.choice(options)\n",
        "        prompt = prompt[:start] + choice + prompt[end+1:]\n",
        "    return prompt\n",
        "\n",
        "# Function to check if the prompt contains dynamic elements\n",
        "def contains_dynamic_elements(prompt):\n",
        "    return '{' in prompt and '}' in prompt\n",
        "\n",
        "def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n",
        "    if randomize_seed:\n",
        "        seed = random.randint(0, MAX_SEED)\n",
        "    return seed\n",
        "\n",
        "# Adjust the save_individual_settings function to include the original dynamic prompt\n",
        "def save_individual_settings(folder_path, image_num, individual_prompt, original_dynamic_prompt, negative_prompt, seed, width, height, guidance_scale, randomize_seed):\n",
        "    filename = f\"settings_image_{image_num}_{str(uuid.uuid4())}.txt\"\n",
        "    full_path = os.path.join(folder_path, filename)\n",
        "    with open(full_path, 'w') as file:\n",
        "        file.write(f\"Original Dynamic Prompt: {original_dynamic_prompt}\\n\")  # Add this line to include the original dynamic prompt\n",
        "        file.write(f\"Processed Prompt: {individual_prompt}\\n\")\n",
        "        file.write(f\"Negative Prompt: {negative_prompt if negative_prompt else 'None'}\\n\")\n",
        "        file.write(f\"Seed: {seed}\\n\")\n",
        "        file.write(f\"Width: {width}\\n\")\n",
        "        file.write(f\"Height: {height}\\n\")\n",
        "        file.write(f\"Guidance Scale: {guidance_scale}\\n\")\n",
        "        file.write(f\"Randomize Seed: {'Yes' if randomize_seed else 'No'}\\n\")\n",
        "    print(f\"Settings for image {image_num} saved to {full_path}\")\n",
        "    return individual_prompt  # Return the individual prompt for further use\n",
        "\n",
        "\n",
        "def save_settings(folder_path, prompt, negative_prompt, seed, width, height, guidance_scale, num_images, randomize_seed):\n",
        "    unique_id = str(uuid.uuid4())\n",
        "    filename = f\"settings_{unique_id}.txt\"\n",
        "    full_path = os.path.join(folder_path, filename)\n",
        "    with open(full_path, 'w') as file:\n",
        "        file.write(f\"Prompt: {prompt}\\n\")\n",
        "        file.write(f\"Negative Prompt: {negative_prompt}\\n\")\n",
        "        file.write(f\"Seed: {seed}\\n\")\n",
        "        file.write(f\"Width: {width}\\n\")\n",
        "        file.write(f\"Height: {height}\\n\")\n",
        "        file.write(f\"Guidance Scale: {guidance_scale}\\n\")\n",
        "        file.write(f\"Number of Images: {num_images}\\n\")\n",
        "        file.write(f\"Randomize Seed: {randomize_seed}\\n\")\n",
        "    print(f\"Settings saved to {full_path}\")\n",
        "\n",
        "\n",
        "def generate(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    use_negative_prompt: bool = False,\n",
        "    seed: int = 0,\n",
        "    width: int = 1024,\n",
        "    height: int = 1024,\n",
        "    guidance_scale: float = 7.5,\n",
        "    randomize_seed: bool = False,\n",
        "    num_images: int = 1,\n",
        "    use_resolution_binning: bool = True,\n",
        "    progress=gr.Progress(track_tqdm=True),\n",
        "):\n",
        "    folder_path = \"/content/drive/My Drive/Playground\"\n",
        "\n",
        "    pipe.to(device)\n",
        "    seed = int(randomize_seed_fn(seed, randomize_seed))\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "    if not use_negative_prompt:\n",
        "        negative_prompt = None\n",
        "\n",
        "    # Check if the prompt contains dynamic elements\n",
        "    dynamic_prompt = contains_dynamic_elements(prompt)\n",
        "\n",
        "    # Save a single settings file if the prompt is not dynamic\n",
        "    if not dynamic_prompt:\n",
        "        save_settings(folder_path, prompt, negative_prompt, seed, width, height, guidance_scale, num_images, randomize_seed)\n",
        "\n",
        "    image_paths = []\n",
        "    for i in range(num_images):\n",
        "        if dynamic_prompt:\n",
        "            # Generate a unique prompt for each image if dynamic\n",
        "            individual_prompt = process_dynamic_prompt(prompt)\n",
        "            # Save individual settings for each image including the original dynamic prompt\n",
        "            save_individual_settings(folder_path, i+1, individual_prompt, prompt, negative_prompt, seed, width, height, guidance_scale, randomize_seed)\n",
        "        else:\n",
        "            # Use the original prompt if not dynamic\n",
        "            individual_prompt = prompt\n",
        "\n",
        "        images = pipe(\n",
        "            prompt=individual_prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_inference_steps=25,\n",
        "            generator=generator,\n",
        "            num_images_per_prompt=1,\n",
        "            use_resolution_binning=use_resolution_binning,\n",
        "            output_type=\"pil\",\n",
        "        ).images\n",
        "\n",
        "        for img in images:\n",
        "            image_path = save_image(img, folder_path)\n",
        "            image_paths.append(image_path)\n",
        "\n",
        "    return image_paths, seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-faV0GduJpO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Gradio Settings (when ready, click on the link \"Running on Public URL\")\n",
        "examples = [\n",
        "    \"neon holography crystal cat\"\n",
        "]\n",
        "\n",
        "css = '''\n",
        ".gradio-container {\n",
        "    max-width: 1680px !important;\n",
        "}\n",
        "h1 {\n",
        "    text-align: center;\n",
        "}\n",
        "'''\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "    gr.DuplicateButton(\n",
        "        value=\"Duplicate Space for private use\",\n",
        "        elem_id=\"duplicate-button\",\n",
        "        visible=os.getenv(\"SHOW_DUPLICATE_BUTTON\") == \"1\",\n",
        "    )\n",
        "    with gr.Group():\n",
        "        with gr.Row():\n",
        "            prompt = gr.Text(\n",
        "                label=\"Prompt\",\n",
        "                show_label=False,\n",
        "                placeholder=\"Enter your prompt\",\n",
        "                container=False,\n",
        "            )\n",
        "            run_button = gr.Button(\"Run\", scale=0)\n",
        "        result = gr.Gallery(label=\"Result\", show_label=False)  # Removed 'columns=NUM_IMAGES_PER_PROMPT'\n",
        "\n",
        "    with gr.Accordion(\"Advanced options\", open=True):\n",
        "        with gr.Row():\n",
        "            use_negative_prompt = gr.Checkbox(label=\"Use negative prompt\", value=True)\n",
        "            negative_prompt = gr.Text(\n",
        "                label=\"Negative prompt\",\n",
        "                max_lines=1,\n",
        "                placeholder=\"Enter a negative prompt\",\n",
        "                visible=True,\n",
        "            )\n",
        "        seed = gr.Slider(\n",
        "            label=\"Seed\",\n",
        "            minimum=0,\n",
        "            maximum=MAX_SEED,\n",
        "            step=1,\n",
        "            value=0,\n",
        "        )\n",
        "        randomize_seed = gr.Checkbox(label=\"Randomize seed\", value=True)\n",
        "        with gr.Row(visible=True):\n",
        "            width = gr.Slider(\n",
        "                label=\"Width\",\n",
        "                minimum=256,\n",
        "                maximum=MAX_IMAGE_SIZE,\n",
        "                step=32,\n",
        "                value=1024,\n",
        "            )\n",
        "            height = gr.Slider(\n",
        "                label=\"Height\",\n",
        "                minimum=256,\n",
        "                maximum=MAX_IMAGE_SIZE,\n",
        "                step=32,\n",
        "                value=1024,\n",
        "            )\n",
        "        with gr.Row():\n",
        "            guidance_scale = gr.Slider(\n",
        "                label=\"Guidance Scale\",\n",
        "                minimum=0.1,\n",
        "                maximum=20,\n",
        "                step=0.1,\n",
        "                value=3.0,\n",
        "            )\n",
        "        num_images = gr.Slider(minimum=1, maximum=200, step=1, label=\"Number of Images\", value=6)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=prompt,\n",
        "        outputs=[result, seed],\n",
        "        fn=generate,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "    )\n",
        "\n",
        "    use_negative_prompt.change(\n",
        "        fn=lambda x: gr.update(visible=x),\n",
        "        inputs=use_negative_prompt,\n",
        "        outputs=negative_prompt,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    gr.on(\n",
        "        triggers=[\n",
        "            prompt.submit,\n",
        "            negative_prompt.submit,\n",
        "            run_button.click,\n",
        "        ],\n",
        "        fn=generate,\n",
        "        inputs=[\n",
        "            prompt,\n",
        "            negative_prompt,\n",
        "            use_negative_prompt,\n",
        "            seed,\n",
        "            width,\n",
        "            height,\n",
        "            guidance_scale,\n",
        "            randomize_seed,\n",
        "            num_images,  # Added 'num_images' here\n",
        "        ],\n",
        "        outputs=[result, seed],\n",
        "        api_name=\"run\",\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue(max_size=20).launch(inline=False)  # Add 'inline=False' here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQwCd6mV58X"
      },
      "source": [
        "My Colabs:<br><br>\n",
        "\n",
        "â€¢\tAnimagine XL 2.0: https://colab.research.google.com/drive/1U9L8MinRDl6uF6ia-6N1URIfzXpy3SGS?usp=sharing\n",
        "\n",
        "â€¢\tSDXL-DPO: https://colab.research.google.com/drive/15f1fc6krTHaRPCRhUpWz6M0V1mnyOZtQ?usp=sharing\n",
        "\n",
        "â€¢\tDreamlike Photoreal 2.0: https://colab.research.google.com/drive/1ZjbbuledqapwnXVOFc6RxmTgtPi3Dd3Z?usp=sharing\n",
        "\n",
        "â€¢\tStable Diffusion SDXL + Kandinsky 3 + Playground V2: https://colab.research.google.com/drive/16ptLGQvzVy8V_LdNe0d0hADSQpjuUJ62?usp=sharing\n",
        "\n",
        "â€¢\tPlayGround V2: https://colab.research.google.com/drive/1fXyZ3KiZpmUa5LVa1Vw9EfKoYtbkZLah?usp=sharing\n",
        "\n",
        "â€¢\tStable Video Diffusion: https://colab.research.google.com/drive/1y-vVm_PhDjpI6E_Yo6yVxYkdAfjm-6U0?usp=sharing\n",
        "\n",
        "â€¢\tAudioCraft MusicGen: https://colab.research.google.com/drive/1eHbMw7yTvTH_8oelN86ES55upGXa2KN3?usp=sharing\n",
        "\n",
        "â€¢\tQES MusicGEN:Â https://colab.research.google.com/drive/1eHbMw7yTvTH_8oelN86ES55upGXa2KN3?usp=sharing\n",
        "\n",
        "â€¢\tGFPGAN Face Restoration:Â https://colab.research.google.com/drive/1ypBZ8MGFqXz3Vte-yuvCTHL-t3xTLuD3?usp=sharing\n",
        "\n",
        "â€¢\tImage-to-Text-to-Image:Â https://colab.research.google.com/drive/1zsG6ruSF_Rk8Yw8OeqA0746_GVjV8Y18?usp=sharing\n",
        "\n",
        "â€¢\tKandinsky 2.1 + Symmetry + Dynamic Prompting + CSV + Upscaling:Â https://colab.research.google.com/drive/18QU-dzz4HzUcXVgVxFP_Ck1qDutXOPrv?usp=sharing\n",
        "\n",
        "â€¢\tKandinsky 2.1 + Automatic Outpainting:Â https://colab.research.google.com/drive/1e9jGVEGnvSaHqKdjzehhzSz-d4kRRYVh?usp=sharing\n",
        "\n",
        "â€¢\tDeforum 7 + Dynamic Prompting:Â https://colab.research.google.com/drive/1hNmWnXnoNE9vXTujD3udJRSYTjSjowvV?usp=sharing\n",
        "\n",
        "â€¢\tKandinsky 3:Â https://colab.research.google.com/drive/13sLgeMJ_-zP7a3LIWmBEOQY3ZIk_Lhuh?usp=sharing\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}