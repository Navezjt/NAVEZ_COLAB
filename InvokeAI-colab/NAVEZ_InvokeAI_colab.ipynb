{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s21vix2PfKF",
        "outputId": "827b4390-0388-4c92-9423-cd89a6de6738",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown #DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NrgcDwZxgDOe"
      },
      "outputs": [],
      "source": [
        "#@markdown #PC\n",
        "%cd /content\n",
        "!git clone -b v3.0.0 https://github.com/Navezjt/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.20 triton==2.0.0 -U\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FTbyyqfXqRLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2d58d6-ba59-40ff-d015-3cec9a145a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InvokeAI\n",
            "--2023-07-24 21:30:33--  https://raw.githubusercontent.com/Navezjt/NAVEZ_COLAB/main/InvokeAI-colab/INITIAL_MODELS.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4956 (4.8K) [text/plain]\n",
            "Saving to: ‘/content/models.yaml’\n",
            "\n",
            "/content/models.yam 100%[===================>]   4.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-24 21:30:33 (66.5 MB/s) - ‘/content/models.yaml’ saved [4956/4956]\n",
            "\n",
            "2023-07-24 21:30:40.196595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;20m[2023-07-24 21:30:47,752]::[InvokeAI]::INFO --> Your InvokeAI root directory is not set up. Calling invokeai-configure.\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,801]::[InvokeAI]::INFO --> ** INITIALIZING INVOKEAI RUNTIME DIRECTORY **\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,808]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,935]::[InvokeAI]::INFO --> Scanned 5 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,998]::[InvokeAI]::INFO --> CHECKING/UPDATING SUPPORT MODELS\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,998]::[InvokeAI]::INFO --> Installing ESRGAN Upscaling models...\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:47,998]::[InvokeAI]::INFO --> Installing RealESRGAN_x4plus.pth model file https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth...\u001b[0m\n",
            "RealESRGAN_x4plus.pth: 67.1MiB [00:01, 49.0MiB/s]               \n",
            "\u001b[38;20m[2023-07-24 21:30:49,612]::[InvokeAI]::INFO --> ...downloaded successfully\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:49,612]::[InvokeAI]::INFO --> Installing RealESRGAN_x4plus_anime_6B.pth model file https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth...\u001b[0m\n",
            "RealESRGAN_x4plus_anime_6B.pth: 17.9MiB [00:00, 270MiB/s]       \n",
            "\u001b[38;20m[2023-07-24 21:30:49,856]::[InvokeAI]::INFO --> ...downloaded successfully\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:49,857]::[InvokeAI]::INFO --> Installing ESRGAN_SRx4_DF2KOST_official.pth model file https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/ESRGAN_SRx4_DF2KOST_official-ff704c30.pth...\u001b[0m\n",
            "ESRGAN_SRx4_DF2KOST_official-ff704c30.pth: 66.9MiB [00:01, 61.5MiB/s]               \n",
            "\u001b[38;20m[2023-07-24 21:30:51,197]::[InvokeAI]::INFO --> ...downloaded successfully\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:51,197]::[InvokeAI]::INFO --> Installing RealESRGAN_x2plus.pth model file https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth...\u001b[0m\n",
            "RealESRGAN_x2plus.pth: 67.1MiB [00:01, 47.6MiB/s]               \n",
            "\u001b[38;20m[2023-07-24 21:30:53,285]::[InvokeAI]::INFO --> ...downloaded successfully\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:30:53,285]::[InvokeAI]::INFO --> Downloading core tokenizers and text encoders\u001b[0m\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 189kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 1.41MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 1.92MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.93MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 5.75MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 45.8MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 3.36MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 9.44MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 23.2MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:07<00:00, 232MB/s]\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 13.0MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 1.86MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.52MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 824/824 [00:00<00:00, 5.53MB/s]\n",
            "Downloading (…)_encoder/config.json: 100% 633/633 [00:00<00:00, 4.43MB/s]\n",
            "Downloading model.safetensors: 100% 1.36G/1.36G [00:13<00:00, 98.0MB/s]\n",
            "\u001b[38;20m[2023-07-24 21:31:34,996]::[InvokeAI]::INFO --> Downloading stable diffusion VAE\u001b[0m\n",
            "Downloading (…)lve/main/config.json: 100% 547/547 [00:00<00:00, 3.20MB/s]\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 279MB/s]\n",
            "\u001b[38;20m[2023-07-24 21:31:37,889]::[InvokeAI]::INFO --> Downloading safety checker\u001b[0m\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 1.98MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 4.55k/4.55k [00:00<00:00, 24.9MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.22G/1.22G [00:04<00:00, 244MB/s]\n",
            "\u001b[38;20m[2023-07-24 21:31:52,652]::[InvokeAI]::INFO --> DOWNLOADING DIFFUSION WEIGHTS\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:31:52,655]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:31:52,768]::[InvokeAI]::INFO --> Scanned 5 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2023-07-24 21:31:52,789]::[InvokeAI]::INFO --> Installing runwayml/stable-diffusion-v1-5 [1/1]\u001b[0m\n",
            "Downloading (…)ain/model_index.json: 100% 541/541 [00:00<00:00, 3.39MB/s]\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n",
            "Downloading (…)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 617/617 [00:00<00:00, 3.36MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 308/308 [00:00<00:00, 1.87MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 3.37MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/492M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.04MB/s]\n",
            "Fetching 13 files:   8% 1/13 [00:01<00:12,  1.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 806/806 [00:00<00:00, 3.98MB/s]\n",
            "\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 1.83MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   6% 31.5M/492M [00:00<00:01, 301MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)7f0/unet/config.json: 100% 743/743 [00:00<00:00, 4.43MB/s]\n",
            "\n",
            "Downloading (…)57f0/vae/config.json: 100% 547/547 [00:00<00:00, 1.95MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  15% 73.4M/492M [00:00<00:01, 341MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.27MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:  23% 115M/492M [00:00<00:01, 263MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   0% 10.5M/3.44G [00:00<00:34, 98.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 21.0M/335M [00:00<00:01, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  30% 147M/492M [00:00<00:01, 213MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   1% 31.5M/3.44G [00:00<00:26, 127MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 41.9M/335M [00:00<00:01, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   2% 52.4M/3.44G [00:00<00:23, 146MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 62.9M/335M [00:00<00:01, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  36% 178M/492M [00:00<00:01, 173MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   2% 73.4M/3.44G [00:00<00:25, 132MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  25% 83.9M/335M [00:00<00:01, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  40% 199M/492M [00:01<00:01, 154MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  31% 105M/335M [00:00<00:01, 119MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   3% 94.4M/3.44G [00:00<00:35, 94.7MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  45% 220M/492M [00:01<00:02, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 126M/335M [00:01<00:01, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   3% 115M/3.44G [00:01<00:36, 90.1MB/s] \u001b[A\n",
            "\n",
            "Downloading model.safetensors:  49% 241M/492M [00:01<00:02, 98.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   4% 126M/3.44G [00:01<00:37, 88.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 147M/335M [00:01<00:01, 98.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   4% 136M/3.44G [00:01<00:37, 87.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  47% 157M/335M [00:01<00:01, 95.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 168M/335M [00:01<00:01, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  53% 262M/492M [00:02<00:02, 84.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   4% 147M/3.44G [00:01<00:44, 74.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  55% 273M/492M [00:02<00:02, 86.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 189M/335M [00:01<00:01, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   5% 168M/3.44G [00:01<00:36, 88.5MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  60% 294M/492M [00:02<00:02, 95.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   5% 178M/3.44G [00:01<00:39, 81.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 210M/335M [00:01<00:01, 100MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 220M/335M [00:02<00:01, 98.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  64% 315M/492M [00:02<00:01, 91.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   6% 199M/3.44G [00:02<00:37, 86.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 231M/335M [00:02<00:01, 97.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  66% 325M/492M [00:02<00:01, 91.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   6% 210M/3.44G [00:02<00:38, 83.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 241M/335M [00:02<00:01, 91.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  68% 336M/492M [00:02<00:01, 88.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 252M/335M [00:02<00:00, 90.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   6% 220M/3.44G [00:02<00:39, 82.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  70% 346M/492M [00:02<00:01, 88.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 262M/335M [00:02<00:00, 92.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 231M/3.44G [00:02<00:40, 79.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  72% 357M/492M [00:03<00:01, 84.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 273M/335M [00:02<00:00, 85.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 241M/3.44G [00:02<00:38, 84.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  85% 283M/335M [00:02<00:00, 89.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 252M/3.44G [00:02<00:37, 85.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  77% 377M/492M [00:03<00:01, 88.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   8% 262M/3.44G [00:02<00:36, 86.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  88% 294M/335M [00:02<00:00, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  79% 388M/492M [00:03<00:01, 82.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 304M/335M [00:03<00:00, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   8% 273M/3.44G [00:03<00:46, 67.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  81% 398M/492M [00:03<00:01, 73.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  94% 315M/335M [00:03<00:00, 76.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   9% 294M/3.44G [00:03<00:39, 78.8MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  85% 419M/492M [00:03<00:00, 82.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:03<00:00, 84.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:03<00:00, 94.7MB/s]\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   9% 315M/3.44G [00:03<00:38, 80.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  89% 440M/492M [00:04<00:00, 85.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   9% 325M/3.44G [00:03<00:37, 82.0MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  92% 451M/492M [00:04<00:00, 72.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  10% 336M/3.44G [00:05<02:11, 23.6MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  94% 461M/492M [00:06<00:01, 17.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  10% 346M/3.44G [00:05<02:12, 23.4MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  11% 367M/3.44G [00:05<01:25, 35.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors: 100% 492M/492M [00:06<00:00, 77.1MB/s]\n",
            "Fetching 13 files:  38% 5/13 [00:07<00:12,  1.51s/it]\n",
            "Downloading (…)ch_model.safetensors:  11% 388M/3.44G [00:05<01:02, 48.4MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  12% 409M/3.44G [00:06<00:47, 64.3MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  13% 440M/3.44G [00:06<00:34, 88.1MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  14% 472M/3.44G [00:06<00:24, 119MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  14% 493M/3.44G [00:07<01:15, 39.1MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  15% 514M/3.44G [00:08<01:03, 46.2MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  16% 535M/3.44G [00:08<00:49, 58.9MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  16% 566M/3.44G [00:08<00:36, 79.7MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  18% 608M/3.44G [00:08<00:24, 116MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  18% 629M/3.44G [00:08<00:23, 121MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  19% 650M/3.44G [00:08<00:21, 132MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  20% 682M/3.44G [00:08<00:17, 161MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  21% 713M/3.44G [00:09<00:15, 179MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  22% 744M/3.44G [00:09<00:13, 204MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  23% 776M/3.44G [00:09<00:12, 216MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  24% 818M/3.44G [00:09<00:10, 243MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  25% 849M/3.44G [00:09<00:10, 248MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  26% 881M/3.44G [00:09<00:10, 256MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  27% 912M/3.44G [00:09<00:09, 260MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  27% 944M/3.44G [00:09<00:09, 258MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  28% 975M/3.44G [00:10<00:09, 264MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  29% 1.01G/3.44G [00:10<00:09, 265MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  30% 1.04G/3.44G [00:10<00:08, 271MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  31% 1.07G/3.44G [00:10<00:08, 272MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  32% 1.10G/3.44G [00:10<00:08, 270MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  33% 1.13G/3.44G [00:10<00:08, 270MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  34% 1.16G/3.44G [00:10<00:12, 181MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  35% 1.21G/3.44G [00:11<00:10, 213MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  36% 1.24G/3.44G [00:11<00:10, 217MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  37% 1.27G/3.44G [00:11<00:10, 213MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  38% 1.30G/3.44G [00:11<00:09, 223MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  39% 1.33G/3.44G [00:12<00:34, 60.6MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  39% 1.35G/3.44G [00:13<00:30, 68.6MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  40% 1.37G/3.44G [00:13<00:26, 77.2MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  41% 1.39G/3.44G [00:13<00:22, 90.2MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  41% 1.43G/3.44G [00:13<00:16, 120MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  42% 1.46G/3.44G [00:13<00:13, 143MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  43% 1.49G/3.44G [00:13<00:12, 154MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  44% 1.51G/3.44G [00:13<00:11, 164MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  45% 1.54G/3.44G [00:13<00:10, 187MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  46% 1.57G/3.44G [00:14<00:08, 207MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  47% 1.60G/3.44G [00:14<00:08, 227MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  48% 1.64G/3.44G [00:14<00:07, 233MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  48% 1.67G/3.44G [00:14<00:07, 244MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  49% 1.70G/3.44G [00:14<00:07, 246MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  50% 1.73G/3.44G [00:14<00:06, 246MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  51% 1.76G/3.44G [00:14<00:06, 252MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  52% 1.80G/3.44G [00:14<00:06, 272MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  53% 1.84G/3.44G [00:15<00:05, 276MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  55% 1.88G/3.44G [00:15<00:05, 290MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  56% 1.92G/3.44G [00:15<00:05, 300MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  57% 1.95G/3.44G [00:15<00:04, 302MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  58% 1.99G/3.44G [00:15<00:04, 308MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  59% 2.03G/3.44G [00:15<00:04, 317MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  60% 2.08G/3.44G [00:15<00:04, 321MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  62% 2.12G/3.44G [00:16<00:04, 272MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  63% 2.15G/3.44G [00:16<00:04, 266MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  63% 2.18G/3.44G [00:16<00:04, 268MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  64% 2.21G/3.44G [00:16<00:04, 261MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  65% 2.24G/3.44G [00:16<00:04, 258MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  66% 2.28G/3.44G [00:16<00:04, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  67% 2.31G/3.44G [00:16<00:04, 259MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  68% 2.34G/3.44G [00:16<00:04, 258MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  69% 2.37G/3.44G [00:17<00:04, 255MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  70% 2.40G/3.44G [00:17<00:04, 250MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  71% 2.43G/3.44G [00:17<00:03, 251MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  72% 2.46G/3.44G [00:17<00:03, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  73% 2.50G/3.44G [00:17<00:03, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  74% 2.53G/3.44G [00:17<00:03, 253MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  74% 2.56G/3.44G [00:17<00:03, 246MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  75% 2.59G/3.44G [00:17<00:03, 255MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  76% 2.62G/3.44G [00:18<00:03, 241MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  77% 2.65G/3.44G [00:18<00:04, 177MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  78% 2.68G/3.44G [00:18<00:03, 193MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  79% 2.72G/3.44G [00:18<00:03, 206MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  80% 2.75G/3.44G [00:18<00:03, 198MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  81% 2.78G/3.44G [00:18<00:03, 200MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  82% 2.81G/3.44G [00:23<00:27, 23.0MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  83% 2.84G/3.44G [00:23<00:19, 31.4MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  84% 2.87G/3.44G [00:23<00:13, 42.5MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  84% 2.90G/3.44G [00:23<00:09, 57.2MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  86% 2.95G/3.44G [00:23<00:06, 81.0MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  87% 2.98G/3.44G [00:23<00:04, 93.8MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  88% 3.01G/3.44G [00:23<00:03, 114MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  88% 3.04G/3.44G [00:24<00:02, 137MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  89% 3.07G/3.44G [00:24<00:02, 162MB/s]\u001b[A"
          ]
        }
      ],
      "source": [
        "#@markdown #RUN\n",
        "%cd /content/InvokeAI/\n",
        "!wget https://raw.githubusercontent.com/Navezjt/NAVEZ_COLAB/main/InvokeAI-colab/INITIAL_MODELS.yaml -O /content/models.yaml\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --default_only --yes\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
