{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§ lama-cleaner_Navez âš¡\n",
        "\n",
        "*if you find this helpful consider becoming a member on patreon, subscribe to my youtube for Ai applications guides*\n",
        "\n",
        "[![Patreon](https://img.shields.io/badge/Patreon-Support-orange?style=rounded-square&logo=patreon)](https://www.patreon.com/user?u=98917275)\n",
        "[![Youtube](https://img.shields.io/badge/Youtube-Subscribe-red?style=rounded-square&logo=youtube)](https://www.youtube.com/@clementetumbajulcan4712)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-Visit-blue?style=rounded-square&logo=github)](https://github.com/Navezjt)\n",
        "[![Huggingface](https://img.shields.io/badge/Huggingface-visit-yellow?style=rounded-square&logo=huggingface)](https://huggingface.co/JCTN)\n",
        "[![Instagram](https://img.shields.io/badge/Instagarm-Follow-pink?style=rounded-square&logo=Instagram)](https://Instagram.com/joeltumbajulca)\n",
        "\n"
      ],
      "metadata": {
        "id": "OX_y2Gokts9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk9wAWLScQ1R",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install package\n",
        "#@markdown # 1. Install package\n",
        "#@markdown Github Project: https://github.com/Navezjt/lama-cleaner\n",
        "\n",
        "!pip3 install lama-cleaner pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download model\n",
        "#@markdown # 2. Downloading model\n",
        "init_model = 'lama' #@param ['lama', 'sd1.5', 'paint_by_example']\n",
        "port = 4242\n",
        "\n",
        "#@markdown # !! Important Notes !!\n",
        "#@markdown Please stop this block after model download finish (seeing `running on http://0.0.0.0:4242/` in the log)\n",
        "\n",
        "!lama-cleaner --host 0.0.0.0 --port $port --model $init_model"
      ],
      "metadata": {
        "id": "nF5-ak8F4Iem",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Setup ngrok\n",
        "\n",
        "#@markdown # 3. Setup ngrok\n",
        "#@markdown Get a free [ngrok](https://ngrok.com/) account and copy your authtoken [here](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "ngrok_authtoken = 'Paste ngrok token here' #@param {type: 'string'}\n",
        "\n",
        "!ngrok authtoken $ngrok_authtoken\n",
        "\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"ngrok public url: {public_url}.\")"
      ],
      "metadata": {
        "id": "qKe0DDAUgGBw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Start Lama Cleaner server\n",
        "#@markdown # 4. Start Lama Cleaner server\n",
        "#@markdown When you see `Running on http://0.0.0.0:4242/' in the log`, please open **ngrok public link**\n",
        "\n",
        "\n",
        "!lama-cleaner --host 0.0.0.0 --port $port --model $init_model"
      ],
      "metadata": {
        "id": "AlZ4devxcxCS",
        "outputId": "9fbf032c-f4aa-46d1-a76a-7819d4aab5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Platform: Linux-\u001b[1;36m5.15\u001b[0m.\u001b[1;36m109\u001b[0m+-x86_64-with-glibc2.\u001b[1;36m35\u001b[0m\n",
            "- Python version: \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m\n",
            "- torch: \u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118\n",
            "- torchvision: \u001b[1;36m0.15\u001b[0m.\u001b[1;36m2\u001b[0m+cu118\n",
            "- Pillow: \u001b[1;36m9.4\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "- diffusers: \u001b[1;36m0.16\u001b[0m.\u001b[1;36m1\u001b[0m\n",
            "- transformers: \u001b[1;36m4.27\u001b[0m.\u001b[1;36m4\u001b[0m\n",
            "- opencv-python: \u001b[1;92m4.8.0.76\u001b[0m\n",
            "- xformers: N/A\n",
            "- accelerate: N/A\n",
            "- lama-cleaner: \u001b[1;36m1.2\u001b[0m.\u001b[1;36m3\u001b[0m\n",
            "- rembg: N/A\n",
            "- realesrgan: N/A\n",
            "- gfpgan: N/A\n",
            "\n",
            "2023-08-16 22:56:08.427365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2023-08-16 22:56:10.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mLoading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\u001b[0m\n",
            "Running on http://127.0.0.1:4242\n",
            " * Running on http://172.28.0.12:4242\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:23] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:23] \"GET /static/js/main.1fda6320.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:23] \"GET /static/css/main.ce986cc8.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:24] \"GET /server_config HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:24] \"GET /inputimage HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:24] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:24] \"GET /is_desktop HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:25] \"GET /static/media/Inter-roman.var.ba4caefcdf5b36b438db.woff2 HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:25] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:56:46] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 22:57:05.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (675, 450, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 22:57:05.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-08-16 22:57:05.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (680, 456, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 22:57:14.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 8918.614625930786ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 22:57:14] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:58:28] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 22:58:48.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (675, 450, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 22:58:48.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-08-16 22:58:48.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (680, 456, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 22:58:49.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 677.1700382232666ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 22:58:49] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:59:34] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 22:59:51] \"GET /static/media/coffee-machine-lineal.ee32631219cc3986f861.gif HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 23:00:39] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 23:00:39] \"GET /model_downloaded/sd1.5 HTTP/1.1\" 200 -\n",
            "Downloading (â€¦)p16/model_index.json: 100% 550/550 [00:00<00:00, 1.45MB/s]\n",
            "safety_checker/model.safetensors not found\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading (â€¦)_checker/config.json: 100% 4.75k/4.75k [00:00<00:00, 17.6MB/s]\n",
            "\n",
            "Downloading (â€¦)cheduler_config.json: 100% 287/287 [00:00<00:00, 1.63MB/s]\n",
            "\n",
            "Downloading (â€¦)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (â€¦)_encoder/config.json: 100% 635/635 [00:00<00:00, 3.75MB/s]\n",
            "\n",
            "\n",
            "Downloading (â€¦)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.06MB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:13,  1.05it/s]\n",
            "\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.61MB/s]\n",
            "\n",
            "\n",
            "Downloading pytorch_model.bin:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)okenizer_config.json: 100% 821/821 [00:00<00:00, 5.76MB/s]\n",
            "\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 4.10MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)6e5/unet/config.json: 100% 810/810 [00:00<00:00, 4.15MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)66e5/vae/config.json: 100% 613/613 [00:00<00:00, 3.08MB/s]\n",
            "\n",
            "\n",
            "Downloading pytorch_model.bin:   4% 10.5M/246M [00:00<00:02, 86.3MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   2% 10.5M/608M [00:00<00:06, 97.3MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  13% 31.5M/246M [00:00<00:01, 136MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 4.37MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:   5% 31.5M/608M [00:00<00:04, 117MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  21% 52.4M/246M [00:00<00:01, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   1% 10.5M/1.72G [00:00<00:26, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   6% 10.5M/167M [00:00<00:01, 92.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:   9% 52.4M/608M [00:00<00:05, 105MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   1% 21.0M/1.72G [00:00<00:25, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  30% 73.4M/246M [00:00<00:01, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  13% 21.0M/167M [00:00<00:01, 74.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  12% 73.4M/608M [00:03<00:33, 15.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   2% 41.9M/1.72G [00:03<02:33, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  38% 94.4M/246M [00:03<00:08, 17.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  19% 31.5M/167M [00:03<00:17, 7.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   3% 52.4M/1.72G [00:03<01:51, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  16% 94.4M/608M [00:03<00:22, 22.9MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  43% 105M/246M [00:03<00:07, 19.8MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   4% 62.9M/1.72G [00:03<01:26, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  17% 105M/608M [00:03<00:18, 26.6MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  25% 41.9M/167M [00:03<00:11, 10.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  47% 115M/246M [00:03<00:05, 23.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   4% 73.4M/1.72G [00:03<01:07, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  19% 115M/608M [00:03<00:15, 30.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  31% 52.4M/167M [00:03<00:07, 15.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  51% 126M/246M [00:04<00:04, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   5% 83.9M/1.72G [00:03<00:56, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  21% 126M/608M [00:04<00:14, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  38% 62.9M/167M [00:05<00:09, 10.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   5% 94.4M/1.72G [00:06<02:36, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  55% 136M/246M [00:07<00:11, 9.22MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  22% 136M/608M [00:08<01:00, 7.80MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   6% 105M/1.72G [00:08<03:12, 8.40MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  60% 147M/246M [00:08<00:10, 9.28MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  44% 73.4M/167M [00:08<00:14, 6.40MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   7% 115M/1.72G [00:08<02:20, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  24% 147M/608M [00:08<00:46, 9.96MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  64% 157M/246M [00:08<00:07, 11.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  50% 83.9M/167M [00:08<00:09, 8.96MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   7% 126M/1.72G [00:08<01:46, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  26% 157M/608M [00:08<00:35, 12.7MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  68% 168M/246M [00:08<00:05, 15.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  56% 94.4M/167M [00:08<00:06, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   8% 136M/1.72G [00:08<01:25, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  72% 178M/246M [00:09<00:03, 18.8MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  28% 168M/608M [00:09<00:27, 15.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  63% 105M/167M [00:08<00:04, 15.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   9% 147M/1.72G [00:08<01:07, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  29% 178M/608M [00:11<00:44, 9.60MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  69% 115M/167M [00:13<00:08, 5.95MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  81% 199M/246M [00:13<00:05, 8.23MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:   9% 157M/1.72G [00:13<03:56, 6.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  31% 189M/608M [00:13<00:55, 7.49MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  85% 210M/246M [00:13<00:03, 10.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  10% 168M/1.72G [00:13<02:58, 8.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  33% 199M/608M [00:13<00:42, 9.72MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  81% 136M/167M [00:13<00:03, 10.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  89% 220M/246M [00:13<00:02, 12.8MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  34% 210M/608M [00:13<00:30, 13.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  10% 178M/1.72G [00:13<02:12, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  36% 220M/608M [00:14<00:22, 17.5MB/s]\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  94% 231M/246M [00:14<00:00, 16.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  88% 147M/167M [00:13<00:01, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  11% 189M/1.72G [00:13<01:40, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading pytorch_model.bin:  98% 241M/246M [00:14<00:00, 20.9MB/s]\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  38% 231M/608M [00:14<00:17, 21.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  94% 157M/167M [00:13<00:00, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  12% 199M/1.72G [00:14<01:15, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  40% 241M/608M [00:15<00:25, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading pytorch_model.bin: 100% 246M/246M [00:15<00:00, 15.8MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin: 100% 167M/167M [00:15<00:00, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin: 100% 167M/167M [00:15<00:00, 10.9MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:  43% 262M/608M [00:15<00:15, 22.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  13% 231M/1.72G [00:15<01:03, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  45% 273M/608M [00:16<00:12, 26.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  14% 241M/1.72G [00:15<00:50, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  15% 252M/1.72G [00:15<00:40, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  48% 294M/608M [00:16<00:07, 39.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  16% 273M/1.72G [00:18<01:31, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  52% 315M/608M [00:18<00:16, 18.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  17% 294M/1.72G [00:18<01:00, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  55% 336M/608M [00:18<00:11, 24.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  18% 304M/1.72G [00:18<00:49, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  59% 357M/608M [00:18<00:07, 33.9MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  62% 377M/608M [00:18<00:04, 46.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  18% 315M/1.72G [00:18<00:47, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  66% 398M/608M [00:19<00:03, 56.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  19% 325M/1.72G [00:18<00:39, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  69% 419M/608M [00:19<00:02, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  20% 346M/1.72G [00:19<00:27, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  72% 440M/608M [00:19<00:02, 78.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  21% 367M/1.72G [00:19<00:21, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  76% 461M/608M [00:19<00:01, 89.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  23% 388M/1.72G [00:19<00:17, 76.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  79% 482M/608M [00:19<00:01, 99.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  24% 409M/1.72G [00:19<00:14, 91.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  83% 503M/608M [00:19<00:00, 105MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  25% 430M/1.72G [00:19<00:13, 97.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  86% 524M/608M [00:20<00:00, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  26% 451M/1.72G [00:19<00:12, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  90% 545M/608M [00:20<00:00, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  27% 472M/1.72G [00:20<00:11, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  93% 566M/608M [00:20<00:00, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  29% 493M/1.72G [00:20<00:10, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin:  97% 587M/608M [00:20<00:00, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  30% 514M/1.72G [00:20<00:09, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading pytorch_model.bin: 100% 608M/608M [00:20<00:00, 29.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 15 files:  27% 4/15 [00:21<01:04,  5.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  32% 556M/1.72G [00:20<00:08, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  34% 587M/1.72G [00:20<00:06, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  36% 619M/1.72G [00:20<00:06, 182MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  37% 640M/1.72G [00:21<00:05, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  38% 661M/1.72G [00:21<00:05, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  40% 692M/1.72G [00:21<00:05, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  41% 713M/1.72G [00:21<00:05, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  43% 734M/1.72G [00:21<00:05, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  45% 765M/1.72G [00:23<00:20, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  46% 786M/1.72G [00:23<00:15, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  47% 807M/1.72G [00:23<00:13, 69.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  48% 828M/1.72G [00:23<00:10, 84.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  50% 860M/1.72G [00:23<00:08, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  51% 881M/1.72G [00:23<00:08, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  52% 902M/1.72G [00:24<00:08, 99.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  54% 923M/1.72G [00:24<00:07, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  55% 944M/1.72G [00:24<00:07, 110MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  56% 965M/1.72G [00:24<00:06, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  57% 986M/1.72G [00:24<00:05, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  59% 1.01G/1.72G [00:24<00:05, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  60% 1.03G/1.72G [00:24<00:05, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  61% 1.05G/1.72G [00:25<00:04, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  62% 1.07G/1.72G [00:25<00:04, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  63% 1.09G/1.72G [00:25<00:04, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  65% 1.11G/1.72G [00:25<00:03, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  66% 1.14G/1.72G [00:25<00:03, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  68% 1.16G/1.72G [00:25<00:03, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  69% 1.18G/1.72G [00:25<00:03, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  71% 1.22G/1.72G [00:26<00:02, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  72% 1.24G/1.72G [00:28<00:15, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  73% 1.26G/1.72G [00:28<00:11, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  75% 1.29G/1.72G [00:28<00:07, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  77% 1.32G/1.72G [00:28<00:04, 81.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  78% 1.34G/1.72G [00:28<00:03, 94.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  80% 1.37G/1.72G [00:28<00:02, 119MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  82% 1.41G/1.72G [00:28<00:02, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  84% 1.44G/1.72G [00:29<00:01, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  85% 1.47G/1.72G [00:29<00:01, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  87% 1.50G/1.72G [00:29<00:01, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  89% 1.53G/1.72G [00:29<00:00, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  91% 1.56G/1.72G [00:29<00:00, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  93% 1.59G/1.72G [00:29<00:00, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  95% 1.63G/1.72G [00:33<00:03, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  96% 1.66G/1.72G [00:33<00:01, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin:  98% 1.68G/1.72G [00:33<00:00, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)on_pytorch_model.bin: 100% 1.72G/1.72G [00:33<00:00, 51.2MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:34<00:00,  2.33s/it]\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "127.0.0.1 - - [16/Aug/2023 23:01:58] \"POST /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:02:17.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:02:17.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (99 > 77). Running this sequence through the model will result in indexing errors\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', intricate details, cinematic, highly detailed, 8 k, 1 6 k, soft details, mdj aesthetics']\n",
            "100% 50/50 [01:28<00:00,  1.76s/it]\n",
            "\u001b[32m2023-08-16 23:03:47.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 90317.06547737122ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:03:48] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:06:09.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:06:09.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            "100% 50/50 [01:26<00:00,  1.74s/it]\n",
            "\u001b[32m2023-08-16 23:07:38.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 88677.96111106873ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:07:39] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:09:34.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:09:34.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            "100% 50/50 [01:26<00:00,  1.74s/it]\n",
            "\u001b[32m2023-08-16 23:11:03.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 88730.3991317749ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:11:03] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:13:36.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:13:36.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            "100% 50/50 [01:26<00:00,  1.73s/it]\n",
            "\u001b[32m2023-08-16 23:15:05.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 88769.8438167572ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:15:06] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:16:23.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:16:23.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            " 48% 24/50 [00:41<00:46,  1.80s/it]127.0.0.1 - - [16/Aug/2023 23:17:06] \"GET /model HTTP/1.1\" 200 -\n",
            "100% 50/50 [01:26<00:00,  1.74s/it]\n",
            "\u001b[32m2023-08-16 23:17:52.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 88858.96444320679ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:17:53] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 23:22:38] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [16/Aug/2023 23:22:38] \"GET /model_downloaded/realisticVision1.4 HTTP/1.1\" 200 -\n",
            "Downloading (â€¦)p16/model_index.json: 100% 586/586 [00:00<00:00, 2.59MB/s]\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading (â€¦)rocessor_config.json: 100% 520/520 [00:00<00:00, 3.98MB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:01<00:16,  1.21s/it]\n",
            "Downloading (â€¦)tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (â€¦)cheduler_config.json: 100% 341/341 [00:00<00:00, 1.67MB/s]\n",
            "\n",
            "\n",
            "Downloading (â€¦)_checker/config.json: 100% 5.01k/5.01k [00:00<00:00, 25.6MB/s]\n",
            "\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 4.38MB/s]\n",
            "\n",
            "Downloading (â€¦)_encoder/config.json: 100% 732/732 [00:00<00:00, 4.50MB/s]\n",
            "\n",
            "Downloading (â€¦)okenizer_config.json: 100% 923/923 [00:00<00:00, 5.64MB/s]\n",
            "\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.36MB/s]\n",
            "\n",
            "Downloading (â€¦)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (â€¦)f1a/unet/config.json: 100% 1.18k/1.18k [00:00<00:00, 6.21MB/s]\n",
            "\n",
            "\n",
            "Downloading (â€¦)7f1a/vae/config.json: 100% 711/711 [00:00<00:00, 3.53MB/s]\n",
            "\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.40MB/s]\n",
            "\u001b[32m2023-08-16 23:22:41.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:22:41.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 0.016689300537109375ms\u001b[0m\n",
            "[2023-08-16 23:22:41,457] ERROR in app: Exception on /inpaint [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2528, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lama_cleaner/server.py\", line 291, in process\n",
            "    res_np_img = model(image, mask, config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lama_cleaner/model_manager.py\", line 64, in __call__\n",
            "    return self.model(image, mask, config)\n",
            "AttributeError: 'ModelManager' object has no attribute 'model'\n",
            "127.0.0.1 - - [16/Aug/2023 23:22:41] \"\u001b[35m\u001b[1mPOST /inpaint HTTP/1.1\u001b[0m\" 500 -\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   2% 10.5M/608M [00:00<00:31, 19.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   4% 10.5M/246M [00:00<00:13, 18.1MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   3% 21.0M/608M [00:00<00:18, 32.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   9% 21.0M/246M [00:00<00:07, 30.3MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   5% 31.5M/608M [00:00<00:14, 40.8MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  13% 31.5M/246M [00:00<00:05, 38.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   1% 10.5M/1.72G [00:00<01:37, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   7% 41.9M/608M [00:01<00:12, 45.5MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  17% 41.9M/246M [00:01<00:04, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   1% 21.0M/1.72G [00:00<00:58, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  21% 52.4M/246M [00:01<00:03, 50.6MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:   9% 52.4M/608M [00:01<00:13, 41.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   2% 31.5M/1.72G [00:00<00:42, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  26% 62.9M/246M [00:01<00:03, 57.5MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  10% 62.9M/608M [00:01<00:10, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   2% 41.9M/1.72G [00:01<00:37, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  30% 73.4M/246M [00:01<00:03, 57.1MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  12% 73.4M/608M [00:01<00:15, 35.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   6% 10.5M/167M [00:01<00:25, 6.07MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  34% 83.9M/246M [00:02<00:05, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   3% 52.4M/1.72G [00:01<01:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  14% 83.9M/608M [00:02<00:16, 30.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  38% 94.4M/246M [00:02<00:04, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   4% 62.9M/1.72G [00:02<00:56, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  16% 94.4M/608M [00:02<00:14, 35.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  43% 105M/246M [00:02<00:03, 40.3MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   4% 73.4M/1.72G [00:02<00:45, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  13% 21.0M/167M [00:02<00:15, 9.26MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  17% 105M/608M [00:02<00:12, 40.2MB/s] \u001b[A\n",
            "\n",
            "Downloading model.safetensors:  47% 115M/246M [00:02<00:03, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   5% 83.9M/1.72G [00:02<00:41, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  19% 115M/608M [00:03<00:11, 41.6MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  51% 126M/246M [00:03<00:02, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  19% 31.5M/167M [00:02<00:10, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  21% 126M/608M [00:03<00:11, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   5% 94.4M/1.72G [00:02<00:42, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  55% 136M/246M [00:03<00:02, 48.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   6% 105M/1.72G [00:02<00:33, 47.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  22% 136M/608M [00:03<00:09, 50.0MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  60% 147M/246M [00:03<00:01, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   7% 115M/1.72G [00:03<00:28, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  25% 41.9M/167M [00:03<00:07, 17.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   7% 126M/1.72G [00:03<00:26, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  64% 157M/246M [00:03<00:01, 57.0MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  26% 157M/608M [00:03<00:07, 61.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   8% 136M/1.72G [00:03<00:23, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  31% 52.4M/167M [00:03<00:05, 22.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  68% 168M/246M [00:03<00:01, 61.0MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  29% 178M/608M [00:03<00:05, 75.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  38% 62.9M/167M [00:03<00:03, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  72% 178M/246M [00:03<00:01, 56.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:   9% 157M/1.72G [00:03<00:21, 72.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  31% 189M/608M [00:04<00:06, 69.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  44% 73.4M/167M [00:03<00:02, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  33% 199M/608M [00:04<00:06, 65.0MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  77% 189M/246M [00:04<00:01, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  10% 168M/1.72G [00:03<00:25, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  50% 83.9M/167M [00:04<00:02, 37.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  34% 210M/608M [00:04<00:06, 62.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  81% 199M/246M [00:04<00:00, 51.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  10% 178M/1.72G [00:03<00:25, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  56% 94.4M/167M [00:04<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  36% 220M/608M [00:04<00:07, 55.0MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  85% 210M/246M [00:04<00:00, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  11% 189M/1.72G [00:04<00:28, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  63% 105M/167M [00:04<00:01, 46.0MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  38% 231M/608M [00:07<00:31, 11.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  89% 220M/246M [00:07<00:02, 11.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  69% 115M/167M [00:07<00:04, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  12% 199M/1.72G [00:06<02:08, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  40% 241M/608M [00:07<00:25, 14.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  94% 231M/246M [00:07<00:01, 13.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  12% 210M/1.72G [00:07<01:49, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  41% 252M/608M [00:07<00:19, 18.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  75% 126M/167M [00:07<00:03, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  98% 241M/246M [00:07<00:00, 17.6MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  43% 262M/608M [00:08<00:14, 23.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors: 100% 246M/246M [00:08<00:00, 30.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  13% 220M/1.72G [00:07<01:28, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  81% 136M/167M [00:07<00:01, 16.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  47% 283M/608M [00:08<00:08, 36.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  88% 147M/167M [00:07<00:00, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  14% 241M/1.72G [00:07<00:53, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  50% 304M/608M [00:08<00:05, 51.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  94% 157M/167M [00:08<00:00, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 167M/167M [00:08<00:00, 20.6MB/s]\n",
            "\n",
            "Downloading model.safetensors:  52% 315M/608M [00:08<00:05, 55.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  16% 283M/1.72G [00:08<00:26, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  55% 336M/608M [00:08<00:03, 73.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  18% 304M/1.72G [00:08<00:20, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  59% 357M/608M [00:08<00:02, 89.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  19% 325M/1.72G [00:08<00:17, 81.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  62% 377M/608M [00:09<00:03, 76.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  20% 346M/1.72G [00:08<00:18, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  64% 388M/608M [00:09<00:02, 74.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  21% 357M/1.72G [00:08<00:19, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  66% 398M/608M [00:09<00:03, 66.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  21% 367M/1.72G [00:09<00:20, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  67% 409M/608M [00:09<00:03, 64.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  22% 377M/1.72G [00:09<00:20, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  69% 419M/608M [00:09<00:02, 67.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  23% 388M/1.72G [00:09<00:21, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  71% 430M/608M [00:10<00:02, 61.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  23% 398M/1.72G [00:09<00:23, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  72% 440M/608M [00:10<00:02, 60.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  24% 409M/1.72G [00:09<00:23, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  24% 419M/1.72G [00:10<00:22, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  74% 451M/608M [00:10<00:03, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  25% 430M/1.72G [00:11<01:01, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  76% 461M/608M [00:12<00:09, 15.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  26% 440M/1.72G [00:11<01:05, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  78% 472M/608M [00:12<00:06, 19.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 482M/608M [00:12<00:05, 25.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  26% 451M/1.72G [00:12<00:53, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  83% 503M/608M [00:12<00:02, 40.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  27% 472M/1.72G [00:12<00:33, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  85% 514M/608M [00:13<00:02, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  28% 482M/1.72G [00:12<00:30, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  88% 535M/608M [00:13<00:01, 61.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  29% 503M/1.72G [00:12<00:20, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  30% 514M/1.72G [00:12<00:18, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  91% 556M/608M [00:13<00:00, 76.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  31% 535M/1.72G [00:12<00:14, 80.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  95% 577M/608M [00:13<00:00, 86.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  32% 556M/1.72G [00:13<00:11, 98.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  34% 577M/1.72G [00:13<00:12, 90.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.safetensors:  98% 598M/608M [00:13<00:00, 70.9MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 608M/608M [00:14<00:00, 43.1MB/s]\n",
            "Fetching 15 files:  27% 4/15 [00:16<00:47,  4.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  35% 598M/1.72G [00:13<00:14, 78.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  35% 608M/1.72G [00:13<00:15, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  36% 619M/1.72G [00:14<00:15, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  37% 629M/1.72G [00:14<00:16, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  37% 640M/1.72G [00:14<00:16, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  38% 650M/1.72G [00:14<00:16, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  38% 661M/1.72G [00:14<00:17, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  39% 671M/1.72G [00:15<00:36, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  40% 682M/1.72G [00:15<00:28, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  41% 703M/1.72G [00:15<00:18, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  42% 724M/1.72G [00:15<00:13, 76.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  43% 744M/1.72G [00:16<00:11, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  45% 765M/1.72G [00:16<00:12, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  45% 776M/1.72G [00:16<00:13, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  46% 786M/1.72G [00:16<00:13, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  46% 797M/1.72G [00:17<00:14, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  47% 807M/1.72G [00:17<00:13, 65.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  48% 818M/1.72G [00:17<00:14, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  48% 828M/1.72G [00:17<00:14, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  49% 839M/1.72G [00:17<00:15, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  49% 849M/1.72G [00:18<00:15, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  50% 860M/1.72G [00:18<00:14, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  51% 870M/1.72G [00:18<00:20, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  51% 881M/1.72G [00:18<00:18, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  52% 891M/1.72G [00:19<00:21, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  52% 902M/1.72G [00:19<00:18, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  53% 912M/1.72G [00:19<00:17, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  54% 923M/1.72G [00:19<00:16, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  54% 933M/1.72G [00:19<00:14, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  55% 944M/1.72G [00:20<00:14, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  56% 954M/1.72G [00:20<00:14, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  56% 965M/1.72G [00:20<00:13, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  57% 975M/1.72G [00:20<00:13, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  57% 986M/1.72G [00:20<00:12, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  58% 996M/1.72G [00:20<00:12, 58.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  59% 1.01G/1.72G [00:21<00:12, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  59% 1.02G/1.72G [00:21<00:13, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  60% 1.03G/1.72G [00:21<00:21, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  61% 1.05G/1.72G [00:22<00:14, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  62% 1.07G/1.72G [00:22<00:09, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  63% 1.08G/1.72G [00:22<00:09, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  63% 1.09G/1.72G [00:22<00:09, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  64% 1.10G/1.72G [00:22<00:09, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  65% 1.11G/1.72G [00:22<00:09, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  65% 1.12G/1.72G [00:23<00:09, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  66% 1.13G/1.72G [00:23<00:09, 62.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  66% 1.14G/1.72G [00:23<00:09, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  67% 1.15G/1.72G [00:23<00:09, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  68% 1.16G/1.72G [00:23<00:09, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  68% 1.17G/1.72G [00:24<00:09, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  69% 1.18G/1.72G [00:24<00:09, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  70% 1.20G/1.72G [00:24<00:09, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  70% 1.21G/1.72G [00:24<00:08, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  71% 1.22G/1.72G [00:24<00:09, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  71% 1.23G/1.72G [00:25<00:09, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  72% 1.24G/1.72G [00:25<00:12, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  73% 1.25G/1.72G [00:26<00:19, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  73% 1.26G/1.72G [00:26<00:22, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  74% 1.28G/1.72G [00:27<00:13, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  76% 1.30G/1.72G [00:27<00:08, 47.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  77% 1.33G/1.72G [00:27<00:05, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  79% 1.35G/1.72G [00:27<00:04, 78.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  80% 1.37G/1.72G [00:28<00:04, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  81% 1.38G/1.72G [00:28<00:04, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  81% 1.39G/1.72G [00:28<00:05, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  82% 1.41G/1.72G [00:30<00:14, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  82% 1.42G/1.72G [00:32<00:25, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  84% 1.44G/1.72G [00:32<00:14, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  85% 1.47G/1.72G [00:32<00:07, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  87% 1.49G/1.72G [00:32<00:05, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  88% 1.52G/1.72G [00:32<00:03, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  90% 1.54G/1.72G [00:33<00:02, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  91% 1.56G/1.72G [00:33<00:02, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  91% 1.57G/1.72G [00:33<00:02, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  92% 1.58G/1.72G [00:33<00:02, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  93% 1.59G/1.72G [00:33<00:02, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  93% 1.60G/1.72G [00:34<00:01, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  94% 1.61G/1.72G [00:34<00:01, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  95% 1.63G/1.72G [00:34<00:01, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  95% 1.64G/1.72G [00:34<00:01, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  96% 1.65G/1.72G [00:34<00:01, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  96% 1.66G/1.72G [00:35<00:01, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  97% 1.67G/1.72G [00:35<00:00, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  98% 1.68G/1.72G [00:35<00:00, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  98% 1.69G/1.72G [00:36<00:01, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors:  99% 1.70G/1.72G [00:37<00:00, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 1.72G/1.72G [00:37<00:00, 46.2MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:39<00:00,  2.66s/it]\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "127.0.0.1 - - [16/Aug/2023 23:23:57] \"POST /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:29:25.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:29:25.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            "100% 50/50 [01:26<00:00,  1.73s/it]\n",
            "\u001b[32m2023-08-16 23:30:54.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 88691.61057472229ms\u001b[0m\n",
            "127.0.0.1 - - [16/Aug/2023 23:30:54] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-16 23:34:53.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1088, 960, 3)\u001b[0m\n",
            "\u001b[32m2023-08-16 23:34:53.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (1088, 960, 3)\u001b[0m\n",
            " 48% 24/50 [00:40<00:46,  1.78s/it]"
          ]
        }
      ]
    }
  ]
}